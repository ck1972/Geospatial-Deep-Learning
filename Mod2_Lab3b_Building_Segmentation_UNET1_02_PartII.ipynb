{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Semantic Segmentation of Aerial Imagery for Building Footprint Extraction Using U-Net: Part II**"
      ],
      "metadata": {
        "id": "Gph9S2d3jEb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required packages\n",
        "Before starting the building footprint extraction workflow using U-Net, we need to install a few essential Python libraries that are not included by default in Google Colab. These installations are done using the pip package manager, and the --quiet flag suppresses verbose output to keep the notebook clean."
      ],
      "metadata": {
        "id": "XXXzN5a6CsX9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHRHvi8ki5ru",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torchgeo --quiet\n",
        "!pip install buildingregulariser --quiet\n",
        "!pip install torchsummary --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import required libraries"
      ],
      "metadata": {
        "id": "UM83pkHpjQfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import rasterio\n",
        "from rasterio import features\n",
        "import shapely.geometry as shp_geom\n",
        "from buildingregulariser import regularize_geodataframe\n",
        "from sklearn.metrics import f1_score, jaccard_score\n",
        "import scipy.ndimage as nd"
      ],
      "metadata": {
        "id": "VkW_y_yVjQ8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive and set the working directory"
      ],
      "metadata": {
        "id": "lkYFBammjUNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/MyDrive/Chit_TR9207')"
      ],
      "metadata": {
        "id": "Vu6iS0jajUoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the raster image and rasterize building footprints"
      ],
      "metadata": {
        "id": "mLr49-bljYe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load raster and geojson\n",
        "\n",
        "# Define the path to the aerial image (GeoTIFF file)\n",
        "img_path = 'TR9207a.tif'\n",
        "\n",
        "# Open the raster image using rasterio\n",
        "with rasterio.open(img_path) as src:\n",
        "    transform = src.transform               # Get the affine transformation (pixel-to-coordinate mapping)\n",
        "    height, width = src.height, src.width   # Extract image dimensions (rows and columns)\n",
        "    raster_crs = src.crs                    # Get the coordinate reference system (CRS) of the raster\n",
        "    image = src.read()                      # Read the raster data as a NumPy array (shape: [bands, height, width])\n",
        "\n",
        "# Read building footprint polygons from the GeoJSON file into a GeoDataFrame\n",
        "gdf = gpd.read_file('Bld_DSG_TR9207.geojson')\n",
        "\n",
        "# Rasterize the vector geometries into a binary mask\n",
        "# Each building polygon is assigned a value of 1, and the background is filled with 0\n",
        "# Rasterize the vector geometries into a binary mask\n",
        "# Each building polygon is assigned a value of 1, and the background is filled with 0\n",
        "mask = features.rasterize(\n",
        "    ((geom, 1) for geom in gdf.geometry),   # Generator of (geometry, value) pairs\n",
        "    out_shape=(height, width),             # Output mask will match the raster's dimensions\n",
        "    transform=transform,                   # Use the same affine transform as the raster\n",
        "    fill=0,                                # Set background (non-building) pixels to 0\n",
        "    dtype=np.uint8                         # Use 8-bit unsigned integer type for the mask\n",
        ")"
      ],
      "metadata": {
        "id": "VYEA-aAEjY3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the custom dataset for patch extraction"
      ],
      "metadata": {
        "id": "NNrYS3InjgA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom PyTorch dataset for aerial image building segmentation\n",
        "class AerialBuildingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image, mask):\n",
        "        self.image = image                  # Multi-band aerial image (NumPy array of shape: [bands, height, width])\n",
        "        self.mask = mask                    # Corresponding binary mask (NumPy array of shape: [height, width])\n",
        "        self.patch_size = 256               # Define the patch size (e.g., 256x256 pixels)\n",
        "        self.bands, self.height, self.width = image.shape  # Extract dimensions from the image\n",
        "\n",
        "        # Generate top-left coordinates for each non-overlapping patch in the image\n",
        "        self.patch_coords = [\n",
        "            (i, j)\n",
        "            for i in range(0, self.height - self.patch_size + 1, self.patch_size)\n",
        "            for j in range(0, self.width - self.patch_size + 1, self.patch_size)\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of patches available\n",
        "        return len(self.patch_coords)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get top-left corner (i, j) of the patch based on index\n",
        "        i, j = self.patch_coords[idx]\n",
        "\n",
        "        # Extract image patch and corresponding mask patch\n",
        "        img_patch = self.image[:, i:i+self.patch_size, j:j+self.patch_size]   # Shape: [bands, patch_size, patch_size]\n",
        "        mask_patch = self.mask[i:i+self.patch_size, j:j+self.patch_size]      # Shape: [patch_size, patch_size]\n",
        "\n",
        "        # Convert both to PyTorch tensors\n",
        "        img_patch = torch.tensor(img_patch, dtype=torch.float32)              # Float tensor for image\n",
        "        mask_patch = torch.tensor(mask_patch, dtype=torch.long)              # Long tensor for mask (for classification)\n",
        "\n",
        "        return img_patch, mask_patch"
      ],
      "metadata": {
        "id": "6kvjt95ZjgX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the dataset and data loaders"
      ],
      "metadata": {
        "id": "XjrIb723BoyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the custom dataset using the full image and mask\n",
        "dataset = AerialBuildingDataset(image, mask)\n",
        "\n",
        "# Define the training set size as 80% of the total dataset\n",
        "train_size = int(0.8 * len(dataset))\n",
        "\n",
        "# Define the test set size as the remaining 20%\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "# Randomly split the dataset into training and testing subsets\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create a DataLoader for the training set\n",
        "# - batch_size=4: feed 4 patches at a time\n",
        "# - shuffle=True: randomly shuffle data each epoch to improve generalization\n",
        "# - drop_last=True: drop the last batch if it's smaller than the batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
        "\n",
        "# Create a DataLoader for the test set\n",
        "# - shuffle=False: maintain original order for evaluation consistency\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
      ],
      "metadata": {
        "id": "1lnAPzNlBpK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the U-Net architecture"
      ],
      "metadata": {
        "id": "wJi5dDJdBrKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define U-Net model for semantic segmentation\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # Helper function: Convolution -> ReLU -> Convolution -> ReLU\n",
        "        def CBR(in_ch, out_ch):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, 3, padding=1),  # 1st Conv layer\n",
        "                nn.ReLU(),                              # ReLU activation\n",
        "                nn.Conv2d(out_ch, out_ch, 3, padding=1), # 2nd Conv layer\n",
        "                nn.ReLU()                               # ReLU activation\n",
        "            )\n",
        "\n",
        "        # Encoder (Downsampling path)\n",
        "        self.enc1 = CBR(3, 64)            # First encoder block (input: RGB image)\n",
        "        self.pool1 = nn.MaxPool2d(2)      # Downsample by factor of 2\n",
        "        self.enc2 = CBR(64, 128)          # Second encoder block\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = CBR(128, 256)         # Third encoder block\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = CBR(256, 512)         # Fourth encoder block\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        # Bottleneck layer (deepest representation)\n",
        "        self.middle = CBR(512, 1024)      # Captures most abstract features\n",
        "\n",
        "        # Decoder (Upsampling path)\n",
        "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, 2)  # Upsample to match encoder-4\n",
        "        self.dec4 = CBR(1024, 512)                      # Decoder block with skip connection from enc4\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, 2, 2)   # Upsample to match encoder-3\n",
        "        self.dec3 = CBR(512, 256)                       # Decoder block with skip connection from enc3\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)   # Upsample to match encoder-2\n",
        "        self.dec2 = CBR(256, 128)                       # Decoder block with skip connection from enc2\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, 2, 2)    # Upsample to match encoder-1\n",
        "        self.dec1 = CBR(128, 64)                        # Decoder block with skip connection from enc1\n",
        "\n",
        "        # Final 1x1 convolution to produce 2-channel output (background vs building)\n",
        "        self.final = nn.Conv2d(64, 2, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder path (contracting)\n",
        "        e1 = self.enc1(x)                # Output shape: [B, 64, H, W]\n",
        "        e2 = self.enc2(self.pool1(e1))   # [B, 128, H/2, W/2]\n",
        "        e3 = self.enc3(self.pool2(e2))   # [B, 256, H/4, W/4]\n",
        "        e4 = self.enc4(self.pool3(e3))   # [B, 512, H/8, W/8]\n",
        "\n",
        "        # Bottleneck\n",
        "        m = self.middle(self.pool4(e4))  # [B, 1024, H/16, W/16]\n",
        "\n",
        "        # Decoder path (expanding) with skip connections\n",
        "        d4 = self.dec4(torch.cat([self.up4(m), e4], dim=1))  # [B, 512, H/8, W/8]\n",
        "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1)) # [B, 256, H/4, W/4]\n",
        "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1)) # [B, 128, H/2, W/2]\n",
        "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1)) # [B, 64, H, W]\n",
        "\n",
        "        # Final prediction map\n",
        "        return self.final(d1)  # Output shape: [B, 2, H, W] (logits for 2 classes)"
      ],
      "metadata": {
        "id": "TM3RIe3aBrjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the U-Net model, optimizer, and loss function"
      ],
      "metadata": {
        "id": "YUzlonxCjlAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the U-Net model and move it to GPU if available, otherwise use CPU\n",
        "model = UNet().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Automatically detect and store the device used (GPU or CPU) for future reference\n",
        "device = next(model.parameters()).device\n",
        "\n",
        "# Initialize the Adam optimizer to update model weights during training\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Define the loss function: CrossEntropyLoss is used for pixel-wise classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Print a summary of the model architecture: layers, output shapes, and parameters\n",
        "summary(model, input_size=(3, 256, 256))"
      ],
      "metadata": {
        "id": "dR7s9uV8B0jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop with early stopping"
      ],
      "metadata": {
        "id": "KOVAOS64B8WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with early stopping\n",
        "# Initialize tracking metrics and early stopping parameters\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "best_val_loss = float('inf')  # Start with worst possible loss\n",
        "early_stopping_counter = 0\n",
        "patience = 5  # Allowed consecutive epochs without improvement\n",
        "best_model_path = 'best_unet_model.pth'  # Path to save best model\n",
        "\n",
        "for epoch in range(20):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    total_loss, correct_train, total_train = 0, 0, 0\n",
        "    for imgs, masks in train_loader:\n",
        "        # Keep only RGB channels and move to device\n",
        "        imgs, masks = imgs[:, :3, :, :].to(device), masks.to(device)\n",
        "\n",
        "        # Forward pass and loss calculation\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(imgs)\n",
        "        loss = criterion(preds, masks)\n",
        "\n",
        "        # Backpropagation and weight update\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        total_loss += loss.item()\n",
        "        pred_labels = torch.argmax(preds, dim=1)  # Get class indices\n",
        "        correct_train += (pred_labels == masks).sum().item()\n",
        "        total_train += masks.numel()  # Total pixels in batch\n",
        "\n",
        "    # Calculate epoch training metrics\n",
        "    train_acc = correct_train / total_train\n",
        "    train_losses.append(total_loss / len(train_loader))\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    # Evaluation phase\n",
        "    model.eval()\n",
        "    test_loss, correct_test, total_test = 0, 0, 0\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for imgs, masks in test_loader:\n",
        "            imgs, masks = imgs[:, :3, :, :].to(device), masks.to(device)\n",
        "            preds = model(imgs)\n",
        "            test_loss += criterion(preds, masks).item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            pred_labels = torch.argmax(preds, dim=1)\n",
        "            correct_test += (pred_labels == masks).sum().item()\n",
        "            total_test += masks.numel()\n",
        "\n",
        "    # Calculate epoch validation metrics\n",
        "    test_acc = correct_test / total_test\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {train_losses[-1]:.4f}, \"\n",
        "          f\"Test Loss = {avg_test_loss:.4f}, \"\n",
        "          f\"Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if avg_test_loss < best_val_loss:\n",
        "        best_val_loss = avg_test_loss\n",
        "        early_stopping_counter = 0\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(\"Model improved. Saving best model.\")\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        print(f\"No improvement. Early stopping counter: {early_stopping_counter}/{patience}\")\n",
        "        if early_stopping_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break"
      ],
      "metadata": {
        "id": "WG_ohfM28xFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize training and test loss"
      ],
      "metadata": {
        "id": "zTzDEvFtB36F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new figure with a custom size for better readability\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training and test loss over epochs in the first subplot\n",
        "plt.subplot(1, 2, 1)  # (1 row, 2 columns, 1st subplot)\n",
        "plt.plot(train_losses, label='Train Loss')  # Plot training loss values\n",
        "plt.plot(test_losses, label='Test Loss')    # Plot test loss values\n",
        "plt.xlabel('Epoch')                         # Label x-axis\n",
        "plt.ylabel('Loss')                          # Label y-axis\n",
        "plt.title('Training and Test Loss')         # Set title of the plot\n",
        "plt.legend()                                # Add legend to distinguish the curves"
      ],
      "metadata": {
        "id": "wFFG_fVjA_zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize training and test accuracy"
      ],
      "metadata": {
        "id": "3qPYyU5oBGO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the second subplot to plot accuracy values\n",
        "plt.subplot(1, 2, 2)  # (1 row, 2 columns, 2nd subplot)\n",
        "plt.plot(train_accuracies, label='Train Accuracy')  # Plot training accuracy over epochs\n",
        "plt.plot(test_accuracies, label='Test Accuracy')    # Plot test accuracy over epochs\n",
        "plt.xlabel('Epoch')                                 # Label x-axis as 'Epoch'\n",
        "plt.ylabel('Accuracy')                              # Label y-axis as 'Accuracy'\n",
        "plt.title('Training and Test Accuracy')             # Title for the accuracy plot\n",
        "plt.legend()                                        # Show legend to differentiate curves\n",
        "\n",
        "# Adjust subplot layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VytATeOBBGp1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}